<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title></title>
    <link rel="stylesheet" href="style.css">
</head>
<body>

    <header class="hero-image">
        <div class="hero-text">
            
        </div>
    </header>

    <nav>
        <ul class="nav-links">
            <li><a href="#" data-section="introduction" class="active">Lab Introduction</a></li>
            <li><a href="#" data-section="papers">Recent Papers</a></li>
            <li><a href="#" data-section="members">Members</a></li>
            <li><a href="#" data-section="news">News</a></li>
        </ul>
    </nav>

    <main>
        <section id="introduction" class="content-section active">
            <h2>Lab Introduction</h2>
            <p>Welcome to the LLM Lab! We are a research group dedicated to exploring the frontiers of Large Language Models (LLMs). Our work focuses on developing innovative architectures, improving model efficiency, and applying LLMs to solve real-world problems. Our mission is to push the boundaries of what's possible with AI and contribute to the global research community.</p>
        </section>

        <section id="papers" class="content-section">
            <h2>Recent Papers</h2>
            <ul>
                <li><strong>Paper Title 1:</strong> An insightful look into LLM optimization. <br> <em>Authors: John Doe, Jane Smith. Journal of AI Research, 2024.</em></li>
                <li><strong>Paper Title 2:</strong> A new approach to fine-tuning large models. <br> <em>Authors: Jane Smith, Alex Chen. Proceedings of ACL, 2023.</em></li>
                <li><strong>Paper Title 3:</strong> Ethical considerations in LLM development. <br> <em>Authors: Alex Chen, John Doe. AI Ethics Journal, 2023.</em></li>
            </ul>
        </section>

        <section id="members" class="content-section">
            <h2>Members</h2>
            <div class="member-list">
                <div class="member-card">
                    <h3>Dr. John Doe</h3>
                    <p>Director, Professor</p>
                    <p>Research Interests: Model architecture, NLP applications.</p>
                </div>
                <div class="member-card">
                    <h3>Jane Smith</h3>
                    <p>Ph.D. Candidate</p>
                    <p>Research Interests: Fine-tuning methods, data efficiency.</p>
                </div>
                <div class="member-card">
                    <h3>Alex Chen</h3>
                    <p>Research Assistant</p>
                    <p>Research Interests: AI ethics, large-scale training.</p>
                </div>
            </div>
        </section>

        <section id="news" class="content-section">
            <h2>News</h2>
            <div class="news-item">
                <h3>March 15, 2025</h3>
                <p>Our recent paper, "A New Framework for LLM Distillation," has been accepted to NeurIPS 2025.</p>
            </div>
            <div class="news-item">
                <h3>February 20, 2025</h3>
                <p>Jane Smith presented her research on efficient model training at the EMNLP conference.</p>
            </div>
        </section>
    </main>

    <script src="script.js"></script>
</body>
</html>